{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torchquantum as tq\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#全体目光向我看齐，看我看我看我，我觉得这里qccn的卷积for循环也可以用张量，这样大大加速，but现在我没时间搞这玩意儿\n",
    "def R_y(theta):\n",
    "    \"\"\"Generate the R_y rotation matrix for a given theta in degrees.\"\"\"\n",
    "\n",
    "    # 创建并返回R_y(theta)旋转矩阵\n",
    "    return torch.tensor([\n",
    "        [torch.cos(theta / 2), -torch.sin(theta / 2)],\n",
    "        [torch.sin(theta / 2), torch.cos(theta / 2)]\n",
    "    ],dtype=torch.complex64).to(device)  # 或 torch.complex64 如需与复数张量一起使用\n",
    "\n",
    "I = torch.tensor([[1, 0], [0, 1]], dtype=torch.complex64).to(device)\n",
    "\n",
    "CNOT = torch.tensor([\n",
    "    [1, 0, 0, 0],\n",
    "    [0, 1, 0, 0],\n",
    "    [0, 0, 0, 1],\n",
    "    [0, 0, 1, 0]\n",
    "], dtype=torch.complex64).to(device)\n",
    "Z = torch.tensor([[1, 0], [0, -1]], dtype=torch.complex64).to(device)\n",
    "Z1 = torch.kron(torch.kron(torch.kron(Z, I), I), I).to(device)\n",
    "Z2 = torch.kron(torch.kron(torch.kron(I, Z), I), I).to(device)\n",
    "Z3 = torch.kron(torch.kron(torch.kron(I, I), Z), I).to(device)\n",
    "Z4 = torch.kron(torch.kron(torch.kron(I, I), I), Z).to(device)\n",
    "CNOT01 = torch.kron(torch.kron(CNOT, I), I).to(device)\n",
    "CNOT12 = torch.kron(torch.kron(I, CNOT), I).to(device)\n",
    "CNOT23 = torch.kron(torch.kron(I, I), CNOT).to(device)\n",
    "\n",
    "class QuanvolutionFilter(tq.QuantumModule):#\n",
    "    class Qonvlayer(tq.QuantumModule):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.n_wires = 4\n",
    "            self.ry0 = tq.RY(has_params=True, trainable=True)#不要加初始值\n",
    "            self.ry1 = tq.RY(has_params=True, trainable=True)\n",
    "            self.ry2 = tq.RY(has_params=True, trainable=True)\n",
    "            self.ry3 = tq.RY(has_params=True, trainable=True)\n",
    "            self.ry0_parameter = self.ry0.params\n",
    "            self.ry1_parameter = self.ry1.params\n",
    "            self.ry2_parameter = self.ry2.params\n",
    "            self.ry3_parameter = self.ry3.params\n",
    "\n",
    "\n",
    "        @tq.static_support\n",
    "        def forward(self, q_device: tq.QuantumDevice):\n",
    "            self.q_device = q_device\n",
    "            init_state = self.q_device.get_states_1d()\n",
    "            # state = []\n",
    "            # density = []\n",
    "            state = torch.stack([s.unsqueeze(0).T for s in init_state])\n",
    "            #print(states)\n",
    "            density = torch.matmul(state, state.conj().transpose(-2, -1))\n",
    "            # for i in range(q_device.bsz):\n",
    "            #     state.append(init_state[i].unsqueeze(0).T)\n",
    "            #     density.append(torch.outer(state[i].view(-1), state[i].view(-1).conj()))#初始密度矩阵建立\n",
    "            #print(state)\n",
    "            #print(\"________________\")\n",
    "\n",
    "            #这里可以再再ry0左右cnot[3,0]可能效果会好丢丢\n",
    "            self.ry0(self.q_device, wires=0) #cancel\n",
    "            RY0 = torch.kron(torch.kron(torch.kron(R_y(self.ry0_parameter), I), I), I)\n",
    "            #print(self.ry0_parameter)\n",
    "            # for i in range(q_device.bsz):\n",
    "            #     density[i] = RY0 @ density[i] @ RY0.conj().T\n",
    "            density = torch.matmul(torch.matmul(RY0, density), RY0.conj().transpose(-2, -1))\n",
    "            #print(density.shape)\n",
    "\n",
    "            tq.cnot(self.q_device, wires=[0, 1]) #cancel\n",
    "            # for i in range(q_device.bsz):\n",
    "            #     density[i] = CNOT01 @ density[i] @ CNOT01.conj().T\n",
    "            density = torch.matmul(torch.matmul(CNOT01, density), CNOT01.conj().transpose(-2, -1))\n",
    "\n",
    "            self.ry1(self.q_device, wires=1) #cancel\n",
    "            RY1 = torch.kron(torch.kron(torch.kron(I, R_y(self.ry1_parameter)), I), I)\n",
    "            # for i in range(q_device.bsz):\n",
    "            #     density[i] = RY1 @ density[i] @ RY1.conj().T\n",
    "            density = torch.matmul(torch.matmul(RY1, density), RY1.conj().transpose(-2, -1))\n",
    "\n",
    "            tq.cnot(self.q_device, wires=[0, 1]) #cancel\n",
    "            # for i in range(q_device.bsz):\n",
    "            #     density[i] = CNOT01 @ density[i] @ CNOT01.conj().T\n",
    "            density = torch.matmul(torch.matmul(CNOT01, density), CNOT01.conj().transpose(-2, -1))\n",
    "\n",
    "            tq.cnot(self.q_device, wires=[1, 2]) #cancel\n",
    "            # for i in range(q_device.bsz):\n",
    "            #     density[i] = CNOT12 @ density[i] @ CNOT12.conj().T\n",
    "            density = torch.matmul(torch.matmul(CNOT12, density), CNOT12.conj().transpose(-2, -1))\n",
    "\n",
    "            self.ry2(self.q_device, wires=2) #cancel\n",
    "            RY2 = torch.kron(torch.kron(torch.kron(I, I), R_y(self.ry2_parameter)), I)\n",
    "            # for i in range(q_device.bsz):\n",
    "            #     density[i] = RY2 @ density[i] @ RY2.conj().T\n",
    "            density = torch.matmul(torch.matmul(RY2, density), RY2.conj().transpose(-2, -1))\n",
    "\n",
    "            tq.cnot(self.q_device, wires=[1, 2]) #cancel\n",
    "            # for i in range(q_device.bsz):\n",
    "            #     density[i] = CNOT12 @ density[i] @ CNOT12.conj().T\n",
    "            density = torch.matmul(torch.matmul(CNOT12, density), CNOT12.conj().transpose(-2, -1))\n",
    "\n",
    "            tq.cnot(self.q_device, wires=[2, 3]) #cancel\n",
    "            # for i in range(q_device.bsz):\n",
    "            #     density[i] = CNOT23 @ density[i] @ CNOT23.conj().T\n",
    "            density = torch.matmul(torch.matmul(CNOT23, density), CNOT23.conj().transpose(-2, -1))\n",
    "\n",
    "            self.ry3(self.q_device, wires=3) #cancel\n",
    "            RY3 = torch.kron(torch.kron(torch.kron(I, I), I), R_y(self.ry3_parameter))\n",
    "            # for i in range(q_device.bsz):\n",
    "            #     density[i] = RY3 @ density[i] @ RY3.conj().T\n",
    "            density = torch.matmul(torch.matmul(RY3, density), RY3.conj().transpose(-2, -1))\n",
    "\n",
    "            tq.cnot(self.q_device, wires=[2, 3]) #cancel\n",
    "            # for i in range(q_device.bsz):\n",
    "            #     density[i] = CNOT23 @ density[i] @ CNOT23.conj().T\n",
    "            density = torch.matmul(torch.matmul(CNOT23, density), CNOT23.conj().transpose(-2, -1))\n",
    "\n",
    "            return density\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.n_wires = 4\n",
    "\n",
    "        self.encoder = tq.GeneralEncoder(\n",
    "        [   {'input_idx': [0], 'func': 'ry', 'wires': [0]},\n",
    "            {'input_idx': [1], 'func': 'ry', 'wires': [1]},\n",
    "            {'input_idx': [2], 'func': 'ry', 'wires': [2]},\n",
    "            {'input_idx': [3], 'func': 'ry', 'wires': [3]},])\n",
    "        self.q_layer = self.Qonvlayer()   #tq.RandomLayer(n_ops=8, wires=list(range(self.n_wires)))\n",
    "        self.q_layer1 = self.Qonvlayer()\n",
    "        self.q_layer2 = self.Qonvlayer()\n",
    "        self.q_layer3 = self.Qonvlayer()\n",
    "        self.measure = tq.MeasureAll(tq.PauliZ)\n",
    "\n",
    "    def forward(self, x):\n",
    "        bsz = x.shape[0]\n",
    "        size = 8\n",
    "        #print(type(256))\n",
    "        #x = x.view(bsz, size, size)\n",
    "        #print(x.size())\n",
    "        x = torch.squeeze(x)\n",
    "        #print(x.size())\n",
    "        #x = x.view(bsz, size, size)\n",
    "        data_list = []\n",
    "        # self.q_device3 = tq.QuantumDevice(n_wires=self.n_wires, bsz=bsz, record_op=True)\n",
    "        self.q_device = tq.QuantumDevice(n_wires=self.n_wires, bsz=bsz, record_op=True, device=device)\n",
    "        for c in range(0, size-1, 1):\n",
    "            for r in range(0, size-1, 1):\n",
    "                data = torch.transpose(torch.cat((x[:, c, r], x[:, c, r+1], x[:, c+1, r], x[:, c+1, r+1])).view(4, bsz), 0, 1)\n",
    "                # data = torch.cat((x[:, c, r], x[:, c, r+1], x[:, c+1, r], x[:, c+1, r+1])).view(bsz, 4)\n",
    "                # data = data*pi\n",
    "                data = torch.asin(torch.sqrt(data))*2\n",
    "\n",
    "                # print(len(self.q_device0.op_history))\n",
    "                self.q_device.reset_op_history()\n",
    "                self.q_device.reset_states(bsz=bsz)\n",
    "                self.encoder(self.q_device, data)\n",
    "                density = self.q_layer(self.q_device)\n",
    "                out = self.measure(self.q_device)  #cancel\n",
    "                # expectations = []\n",
    "                # for i in range(bsz):\n",
    "                #     expectation_Z1 = torch.trace(Z1 @ density[i]).real\n",
    "                #     expectation_Z2 = torch.trace(Z2 @ density[i]).real\n",
    "                #     expectation_Z3 = torch.trace(Z3 @ density[i]).real\n",
    "                #     expectation_Z4 = torch.trace(Z4 @ density[i]).real\n",
    "                #     expectations.append(torch.tensor([expectation_Z1, expectation_Z2, expectation_Z3, expectation_Z4]))\n",
    "                # expectations_tensor = torch.stack(expectations)\n",
    "                expectation_Z1 = torch.einsum('bij,ji->b', density, Z1).real  # 计算所有批次的迹\n",
    "                expectation_Z2 = torch.einsum('bij,ji->b', density, Z2).real\n",
    "                expectation_Z3 = torch.einsum('bij,ji->b', density, Z3).real\n",
    "                expectation_Z4 = torch.einsum('bij,ji->b', density, Z4).real\n",
    "\n",
    "                # 将所有期望值合并为一个新的张量\n",
    "                expectations_tensor = torch.stack([expectation_Z1, expectation_Z2, expectation_Z3, expectation_Z4],dim=1)\n",
    "\n",
    "\n",
    "                out = out.mean(dim=1).view(bsz, 1).float()*4  # 用mean不用sum,sum下不去\n",
    "                expectations_tensor = expectations_tensor.mean(dim=1).view(bsz, 1).float() * 4\n",
    "                # print(expectations_tensor)\n",
    "                # print(out)\n",
    "                # print(\"-------\")\n",
    "                # out = expectations_tensor.mean(dim=1).view(bsz, 1).float() * 4\n",
    "                # for _ in range(bsz): #我真是天才\n",
    "                #     tmp = out[_][0] - expectations_tensor[_][0]\n",
    "                #     out[_][0] = tmp + out[_][0]\n",
    "                correction = out[:, 0] - expectations_tensor[:, 0]\n",
    "                out[:, 0] = out[:, 0] - correction\n",
    "\n",
    "                data_list.append(out) # 97.3 相当于sum了\n",
    "\n",
    "\n",
    "                # print(data_list)\n",
    "        # print(data_list)\n",
    "\n",
    "        result = torch.cat(data_list, dim=1).float()\n",
    "        # print(result)\n",
    "        return result\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "class Net(nn.Module):\n",
    "    # define nn\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 1, 2, stride=2)\n",
    "        self.ql1 = QuanvolutionFilter()\n",
    "        self.fc1 = nn.Linear(7*7, 10)\n",
    "        self.fc2 = nn.Linear(10*10, 10)\n",
    "\n",
    "    def forward(self, X):\n",
    "            bs = X.shape[0]\n",
    "            X = X.view(bs, 1, 8, 8)\n",
    "            #X = self.conv1(X)\n",
    "            #X = F.relu(X)   #问题在这呀relu后太小了\n",
    "            X = self.ql1(X).to(device)\n",
    "            #print(X[7])\n",
    "            X = F.relu(X)\n",
    "            #print(X.shape)\n",
    "            X = X.view(bs, -1)\n",
    "\n",
    "            X = self.fc1(X)\n",
    "            # X = F.relu(X)\n",
    "            # X = self.fc2(X)\n",
    "            return F.log_softmax(X,dim=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "train_acuracys = []\n",
    "test_acuracys = []\n",
    "train_ensemble_accuracys = []\n",
    "test_ensemble_accuracys = []\n",
    "\n",
    "# px = 0.1\n",
    "# print(\"噪声水平为\",px)\n",
    "batch_size = 64\n",
    "lr = 0.1\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "prev_loss = float('inf')\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([transforms.Resize((8, 8))\n",
    "                                            #, transforms.Grayscale(num_output_channels=1)\n",
    "                                            , torchvision.transforms.ToTensor()\n",
    "                                            #,transforms.Normalize(0.5, 0.5)\n",
    "                                            ])\n",
    "transform_test = torchvision.transforms.Compose([transforms.Resize((8, 8))\n",
    "                                            #,transforms.Grayscale(num_output_channels=1)\n",
    "                                            , torchvision.transforms.ToTensor()\n",
    "                                            #,transforms.Normalize(0.5, 0.5)\n",
    "                                            ])\n",
    "train_dataset = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform_train)\n",
    "#train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataset = datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform_test)\n",
    "\n",
    "selected_classes = [1,3,5,7]#,2,3,4,5,6,7,8,9\n",
    "train_images_per_class = 7\n",
    "test_images_per_class = 3\n",
    "\n",
    "\n",
    "# 过滤函数，用于选择每个类别的指定数量的图像\n",
    "def filter_by_class_fixed_number(dataset, classes, num_per_class):\n",
    "    class_counts = {class_: 0 for class_ in classes}\n",
    "    indices = []\n",
    "    for i in range(len(dataset)):\n",
    "        _, label = dataset[i]\n",
    "        if class_counts.get(label, 0) < num_per_class and label in classes:\n",
    "            indices.append(i)\n",
    "            class_counts[label] += 1\n",
    "            if all(count == num_per_class for count in class_counts.values()):\n",
    "                break\n",
    "    return Subset(dataset, indices)\n",
    "train_dataset = filter_by_class_fixed_number(train_dataset, selected_classes, train_images_per_class )\n",
    "test_dataset = filter_by_class_fixed_number(test_dataset, selected_classes, test_images_per_class )\n",
    "#batch_size = 64  # 或者你选择的其他批次大小\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# AdaBoost 实现\n",
    "num_epochs = 60\n",
    "n_classifiers = 20\n",
    "classifiers = [Net() for _ in range(n_classifiers)]\n",
    "classifier_weights = torch.zeros(n_classifiers, dtype=torch.float)\n",
    "data_weights = torch.ones(len(train_dataset), dtype=torch.float) / len(train_dataset)\n",
    "data_weights.to(device)\n",
    "def update_data_weights(data_weights, classifier, data_loader, classifier_weight):\n",
    "    clf.eval()\n",
    "    data_weights = data_weights.to(device)\n",
    "    classifier_weight = classifier_weight.to(device)\n",
    "    with torch.no_grad():\n",
    "        for i, (data, target) in enumerate(data_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = classifier(data)\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            incorrect = pred.ne(target.view_as(pred)).view(-1).float().to(device)\n",
    "            incorrect[incorrect == 0] = -1\n",
    "            data_weights[i*len(data):(i+1)*len(data)] *= torch.exp(classifier_weight * incorrect)\n",
    "    data_weights /= data_weights.sum()  # 归一化\n",
    "def calculate_error(clf, train_loader, data_weights, device):\n",
    "    clf.eval()\n",
    "    total_error = 0.0\n",
    "    data_weights = data_weights.to(device) \n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = clf(inputs)\n",
    "            predicted= outputs.max(1, keepdim=True)[1]\n",
    "            incorrect = predicted.ne(labels.view_as(predicted)).view(-1)\n",
    "            weighted_error = torch.dot(data_weights[i*len(inputs):(i+1)*len(inputs)], incorrect.float()) / data_weights.sum()\n",
    "            total_error += weighted_error\n",
    "    return total_error.item()\n",
    "\n",
    "def train(clf, device):\n",
    "    clf.eval()        \n",
    "    correct = 0\n",
    "    train_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = clf(inputs)\n",
    "            train_loss += torch.nn.functional.cross_entropy(outputs, labels, reduction='sum').item()\n",
    "            predicted= outputs.argmax(dim=1, keepdim=True)  # 获取最大概率的索引\n",
    "            #_, predicted = torch.max(outputs, 1)\n",
    "            correct += predicted.eq(labels.view_as(predicted)).sum().item()\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    train_acuracy = 100. * correct / len(train_loader.dataset)\n",
    "    train_acuracys.append(train_acuracy)\n",
    "    print('\\nTrain set: Average loss: {:.4f}, Accuracy: {}/{} ({:.4f}%)\\n'.format(\n",
    "        train_loss, correct, len(train_loader.dataset),\n",
    "        train_acuracy))\n",
    "def test(clf, device):\n",
    "    clf.eval()        \n",
    "    correct = 0\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = clf(inputs)\n",
    "            outputs = outputs.to(device)\n",
    "            test_loss += torch.nn.functional.cross_entropy(outputs, labels, reduction='sum').item()\n",
    "            predicted= outputs.argmax(dim=1, keepdim=True)  # 获取最大概率的索引\n",
    "            #_, predicted = torch.max(outputs, 1)\n",
    "            correct += predicted.eq(labels.view_as(predicted)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_acuracy = 100. * correct / len(test_loader.dataset)\n",
    "    test_acuracys.append(test_acuracy)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.4f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        test_acuracy))\n",
    "\n",
    "for i, clf in enumerate(classifiers):\n",
    "    sampler = WeightedRandomSampler(data_weights, len(data_weights))\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler)\n",
    "    optimizer = torch.optim.Adam(clf.parameters())\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        clf.train()\n",
    "        clf.to(device)\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            inputs, labels = inputs.to(device), labels.to(device)#, outputs.to(device)\n",
    "            outputs = clf(inputs)\n",
    "            loss = F.cross_entropy(outputs,labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        # 打印训练集上的平均损失\n",
    "        print(f\"第{i}个分类器，epoch为{epoch+1}/{num_epochs}，Loss: {running_loss / len(train_loader)}\")\n",
    "        train(clf, device)\n",
    "        test(clf, device)\n",
    "\n",
    "    # 计算错误率和分类器权重\n",
    "    error = calculate_error(clf, train_loader, data_weights, device)\n",
    "    classifier_weight = torch.log(torch.tensor((1 - error) / (error+0.00000001))) + torch.log(torch.tensor(4-1))\n",
    "    classifier_weights[i] = classifier_weight\n",
    "\n",
    "    # 更新数据权重\n",
    "    update_data_weights(data_weights, clf, train_loader, classifier_weight)\n",
    "\n",
    "\n",
    "    # 定义强分类器函数\n",
    "    def strong_classifier(data, classifiers, classifier_weights):\n",
    "        final_output = torch.zeros((len(data), 10)).to(device)\n",
    "        for weight, clf in zip(classifier_weights, classifiers):\n",
    "            data, clf = data.to(device), clf.to(device)\n",
    "            weight = weight.to(device)\n",
    "            output = clf(data)\n",
    "            # 使用对数softmax作为弱分类器的输出\n",
    "            final_output += weight * output\n",
    "            #print(weight)\n",
    "        return final_output\n",
    "    # 计算集成模型的准确率\n",
    "    def train_ensemble_accuracy(train_loader, classifiers, classifier_weights):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in train_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                # 使用 strong_classifier 函数获取集成模型的输出\n",
    "                ensemble_output = strong_classifier(data, classifiers, classifier_weights)\n",
    "                # 获取最大预测值的索引作为预测结果\n",
    "                pred = ensemble_output.max(1, keepdim=True)[1]\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "                total += target.size(0)\n",
    "                #print(total)\n",
    "        return correct / total\n",
    "\n",
    "    def test_ensemble_accuracy(test_loader, classifiers, classifier_weights):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                # 使用 strong_classifier 函数获取集成模型的输出\n",
    "                ensemble_output = strong_classifier(data, classifiers, classifier_weights)\n",
    "                # 获取最大预测值的索引作为预测结果\n",
    "                pred = ensemble_output.max(1, keepdim=True)[1].to(device)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "                total += target.size(0)\n",
    "                #print(total)\n",
    "        return correct / total\n",
    "\n",
    "    # 计算准确率\n",
    "    #test_loader = DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
    "    train_ada_accuracy = train_ensemble_accuracy(train_loader, classifiers, classifier_weights)\n",
    "    train_ensemble_accuracys.append(train_ada_accuracy)\n",
    "    print(\"Ensemble Train Accuracy: {:.2f}%\".format(100 * train_ada_accuracy))\n",
    "    test_ada_accuracy = test_ensemble_accuracy(test_loader, classifiers, classifier_weights)\n",
    "    test_ensemble_accuracys.append(test_ada_accuracy)\n",
    "    print(\"Ensemble Test Accuracy: {:.2f}%\".format(100 * test_ada_accuracy))\n",
    "    print('__________________________')\n",
    "    torch.save(train_acuracys, 'train_acuracys.pt')\n",
    "    torch.save(test_acuracys, 'test_acuracys.pt')\n",
    "    torch.save(train_ensemble_accuracys, 'train_ensemble_accuracys.pt')\n",
    "    torch.save(test_ensemble_accuracys, 'test_ensemble_accuracys.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40.464285714285715, 69.67857142857143, 80.60714285714286, 83.46428571428571, 84.96428571428571, 86.92857142857143, 86.10714285714286, 87.42857142857143, 87.96428571428571, 88.57142857142857, 89.35714285714286, 88.89285714285714, 89.39285714285714, 90.42857142857143, 88.28571428571429, 89.57142857142857, 90.89285714285714, 91.82142857142857, 90.39285714285714, 91.57142857142857, 90.85714285714286, 90.35714285714286, 90.82142857142857, 91.92857142857143, 91.82142857142857, 91.57142857142857, 92.78571428571429, 91.64285714285714, 92.67857142857143, 92.03571428571429, 54.785714285714285, 68.5, 75.82142857142857, 78.46428571428571, 80.57142857142857, 83.21428571428571, 83.35714285714286, 83.53571428571429, 84.71428571428571, 84.78571428571429, 85.25, 86.96428571428571, 87.10714285714286, 86.92857142857143, 86.96428571428571, 86.35714285714286, 88.96428571428571, 88.42857142857143, 88.21428571428571, 88.21428571428571, 88.39285714285714, 88.17857142857143, 88.60714285714286, 89.0, 88.82142857142857, 88.78571428571429, 89.17857142857143, 89.60714285714286, 88.78571428571429, 89.17857142857143, 56.92857142857143, 66.64285714285714, 71.92857142857143, 77.42857142857143, 81.42857142857143, 83.5, 83.78571428571429, 85.07142857142857, 87.39285714285714, 87.46428571428571, 87.67857142857143, 86.82142857142857, 87.96428571428571, 87.03571428571429, 89.53571428571429, 89.78571428571429, 90.5, 90.75, 90.60714285714286, 90.14285714285714, 89.5, 90.21428571428571, 90.78571428571429, 90.60714285714286, 91.21428571428571, 90.46428571428571, 90.10714285714286, 92.07142857142857, 91.57142857142857, 90.96428571428571, 22.25, 44.25, 65.32142857142857, 77.35714285714286, 81.46428571428571, 83.82142857142857, 84.25, 86.53571428571429, 87.60714285714286]\n",
      "[37.333333333333336, 60.666666666666664, 73.41666666666667, 78.0, 80.83333333333333, 82.5, 83.0, 84.08333333333333, 84.0, 86.0, 86.16666666666667, 86.08333333333333, 86.41666666666667, 87.08333333333333, 86.58333333333333, 87.91666666666667, 88.08333333333333, 87.83333333333333, 87.5, 89.5, 89.41666666666667, 88.5, 88.66666666666667, 89.75, 90.25, 89.58333333333333, 90.0, 89.91666666666667, 90.66666666666667, 90.5, 52.75, 62.833333333333336, 69.83333333333333, 73.75, 75.75, 77.66666666666667, 78.83333333333333, 77.91666666666667, 80.5, 81.75, 82.0, 82.66666666666667, 82.75, 83.16666666666667, 83.75, 84.5, 84.16666666666667, 84.33333333333333, 84.75, 84.33333333333333, 84.75, 85.5, 85.83333333333333, 85.58333333333333, 85.83333333333333, 85.83333333333333, 86.0, 85.33333333333333, 86.16666666666667, 86.83333333333333, 52.083333333333336, 60.75, 68.66666666666667, 74.5, 78.0, 79.41666666666667, 79.75, 80.75, 80.58333333333333, 82.5, 82.33333333333333, 83.08333333333333, 82.91666666666667, 83.41666666666667, 84.58333333333333, 84.25, 85.41666666666667, 85.16666666666667, 85.08333333333333, 85.83333333333333, 85.83333333333333, 85.75, 86.08333333333333, 86.08333333333333, 85.66666666666667, 86.41666666666667, 86.5, 86.16666666666667, 86.25, 86.75, 24.583333333333332, 42.333333333333336, 63.0, 76.16666666666667, 81.08333333333333, 81.25, 81.5, 83.83333333333333, 83.58333333333333]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "train_acuracys= torch.load('train_acuracys.pt')\n",
    "test_acuracys= torch.load('test_acuracys.pt')\n",
    "print(train_acuracys)\n",
    "print(test_acuracys)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9253571428571429, 0.915, 0.9221428571428572]\n",
      "[0.905, 0.9041666666666667, 0.9]\n"
     ]
    }
   ],
   "source": [
    "train_ensemble_accuracys = torch.load('train_ensemble_accuracys.pt')\n",
    "test_ensemble_accuracys = torch.load('test_ensemble_accuracys.pt')\n",
    "print(train_ensemble_accuracys )\n",
    "print(test_ensemble_accuracys )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n",
      "69\n"
     ]
    }
   ],
   "source": [
    "train_acuracys_single= torch.load('train_acuracys_single.pt')\n",
    "test_acuracys_single= torch.load('test_acuracys_single.pt')\n",
    "\n",
    "print(len(train_acuracys_single))\n",
    "print(len(test_acuracys_single))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchQJH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
